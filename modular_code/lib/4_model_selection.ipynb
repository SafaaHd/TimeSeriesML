{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing sys\n",
    "import sys\n",
    "  \n",
    "# adding src to the system path\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ml_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval_based\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesForestClassifier\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkernel_based\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RocketClassifier\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml_pipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatureset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  make_summary_stats_input, make_series_input\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml_pipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m processing_pipeline, train_traditional_model, test_model, plot_model_result\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load training and test data\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ml_pipeline'"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Step 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from ml_pipeline.featureset import  make_summary_stats_input, make_series_input\n",
    "from ml_pipeline.model import processing_pipeline, train_traditional_model, test_model, plot_model_result\n",
    "\n",
    "# Load training and test data\n",
    "train = pd.read_csv('../input/train/data.csv', parse_dates=['Time']).set_index('Time')\n",
    "test = pd.read_csv('../input/test/data.csv', parse_dates=['Time']).set_index('Time')\n",
    "\n",
    "# Dictionary to store all data configurations\n",
    "data_dict = {'stat': {}, '1col': {}, 'ts': {}}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 2: Data Preprocessing and Feature Engineering\n",
    "\n",
    "# Create summary statistics for traditional ML\n",
    "data_dict['stat']['X_train'], data_dict['stat']['y_train'] = processing_pipeline(\n",
    "    train[-3100:-2900],\n",
    "    window_kwargs={'window_length': 30, 'step_length': 1, 'fh': 0},\n",
    "    feature_func=make_summary_stats_input\n",
    ")\n",
    "data_dict['stat']['X_test'], data_dict['stat']['y_test'] = processing_pipeline(\n",
    "    test[4200:4400],\n",
    "    window_kwargs={'window_length': 30, 'step_length': 1, 'fh': 0},\n",
    "    feature_func=make_summary_stats_input\n",
    ")\n",
    "\n",
    "# Single-column time series\n",
    "data_dict['1col']['X_train'], data_dict['1col']['y_train'] = processing_pipeline(\n",
    "    train[-3100:-2900][['Temperature', 'Status']],\n",
    "    window_kwargs={'window_length': 30, 'step_length': 1, 'fh': 0},\n",
    "    feature_func=make_series_input,\n",
    "    add_first_diffs=False\n",
    ")\n",
    "data_dict['1col']['X_test'], data_dict['1col']['y_test'] = processing_pipeline(\n",
    "    test[4200:4400][['Temperature', 'Status']],\n",
    "    window_kwargs={'window_length': 30, 'step_length': 1, 'fh': 0},\n",
    "    feature_func=make_series_input,\n",
    "    add_first_diffs=False\n",
    ")\n",
    "\n",
    "# Multi-column time series\n",
    "data_dict['ts']['X_train'], data_dict['ts']['y_train'] = processing_pipeline(\n",
    "    train[-3100:-2900],\n",
    "    window_kwargs={'window_length': 30, 'step_length': 1, 'fh': 0},\n",
    "    feature_func=make_series_input,\n",
    "    add_first_diffs=True\n",
    ")\n",
    "data_dict['ts']['X_test'], data_dict['ts']['y_test'] = processing_pipeline(\n",
    "    test[4200:4400],\n",
    "    window_kwargs={'window_length': 30, 'step_length': 1, 'fh': 0},\n",
    "    feature_func=make_series_input,\n",
    "    add_first_diffs=True\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 3: Define Models and Parameter Grids for Model Selection\n",
    "\n",
    "# Define model candidates and parameter grids\n",
    "models = {\n",
    "    \"TimeSeriesForest\": TimeSeriesForestClassifier(),\n",
    "    \"RocketClassifier\": RocketClassifier()\n",
    "}\n",
    "param_grids = {\n",
    "    \"TimeSeriesForest\": {\"n_estimators\": [50, 100]},\n",
    "    \"RocketClassifier\": {\"rocket__num_kernels\": [500, 1000]}\n",
    "}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 4: Model Selection and Training\n",
    "\n",
    "def model_selection(X_train, y_train):\n",
    "    model_results = {}\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        grid = GridSearchCV(model, param_grids[model_name], cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        # Save the best model and its score\n",
    "        model_results[model_name] = {\n",
    "            \"best_model\": grid.best_estimator_,\n",
    "            \"best_score\": grid.best_score_,\n",
    "            \"best_params\": grid.best_params_\n",
    "        }\n",
    "        print(f\"{model_name} - Best Score: {grid.best_score_}, Best Params: {grid.best_params_}\")\n",
    "    \n",
    "    # Select the best model based on the score\n",
    "    best_model_name = max(model_results, key=lambda x: model_results[x][\"best_score\"])\n",
    "    best_model = model_results[best_model_name][\"best_model\"]\n",
    "    print(f\"Selected Model: {best_model_name}\")\n",
    "    \n",
    "    return best_model, model_results\n",
    "\n",
    "# Perform model selection for the summary statistics dataset as an example\n",
    "best_model_stat, stat_model_results = model_selection(data_dict['stat']['X_train'], data_dict['stat']['y_train'])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 5: Testing and Evaluating the Best Model\n",
    "\n",
    "# Test the best selected model on the test data\n",
    "def evaluate_model(model, X_test, y_test, threshold=0.5):\n",
    "    result = test_model(X_test, y_test, model, threshold)\n",
    "    accuracy = (result['residual'] == 0).mean()\n",
    "    print(f\"Accuracy at threshold {threshold}: {accuracy}\")\n",
    "    \n",
    "    # Plot results\n",
    "    plot_model_result(result)\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "accuracy = evaluate_model(best_model_stat, data_dict['stat']['X_test'], data_dict['stat']['y_test'])\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Step 6: Repeat for Other Data Configurations (Optional)\n",
    "# You can repeat model selection and evaluation for the '1col' and 'ts' datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elevator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
